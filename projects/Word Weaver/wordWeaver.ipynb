{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "J1D42emD32Ro"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Sachit\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               phrases\n",
      "0                                                Hey ,\n",
      "1                                                 Hi ,\n",
      "2                                              Hello ,\n",
      "3                                       Good morning ,\n",
      "4                                     Good afternoon ,\n",
      "..                                                 ...\n",
      "563  With 10 years of experience in the mobile indu...\n",
      "564  Please let me know if you’re interested in col...\n",
      "565  She will be providing technical support and as...\n",
      "566  make sure they enjoy the best experience with ...\n",
      "567                                 Feel free to greet\n",
      "\n",
      "[568 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "file = pd.read_json(\"./prompts.json\")\n",
    "prompts = pd.DataFrame(file)\n",
    "print(prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "KhtDxwL_AXFj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'to': 1, 'you': 2, 'i': 3, 'the': 4, 'for': 5, 'your': 6, 'please': 7, 'this': 8, 'a': 9, 'and': 10, 'it': 11, 'in': 12, 'have': 13, 'me': 14, 'my': 15, 'with': 16, 'if': 17, 'would': 18, 'we': 19, 'on': 20, 'be': 21, 'of': 22, 'that': 23, 'our': 24, 'is': 25, 'thank': 26, 'any': 27, 'email': 28, 'as': 29, 'are': 30, 'about': 31, 'so': 32, 'am': 33, 'more': 34, 'know': 35, 'time': 36, 'could': 37, 'let': 38, 'us': 39, 'can': 40, 'like': 41, 'information': 42, 'hope': 43, 'at': 44, 'wanted': 45, 'some': 46, 'attached': 47, 'up': 48, 'help': 49, 'not': 50, 'get': 51, 'wednesday': 52, 'i’m': 53, 'great': 54, 'sorry': 55, 'just': 56, 'appreciate': 57, 'need': 58, 'free': 59, 'best': 60, 'from': 61, 'share': 62, 'was': 63, 'writing': 64, 'all': 65, 'here': 66, 'do': 67, 'will': 68, 'last': 69, 'i’d': 70, 'thanks': 71, 'had': 72, 'make': 73, 'what': 74, 'love': 75, 'keep': 76, 'inform': 77, 'may': 78, 'an': 79, 'out': 80, 'questions': 81, 'again': 82, 'look': 83, 'feedback': 84, 'work': 85, 'subscription': 86, 'forward': 87, 'inconvenience': 88, 'caused': 89, 'how': 90, 'take': 91, 'regret': 92, 'working': 93, 'but': 94, 'check': 95, 'possible': 96, 's': 97, 'been': 98, 'day': 99, 'documents': 100, 'feel': 101, 'understand': 102, 'touch': 103, 'call': 104, 'support': 105, 'has': 106, 'soon': 107, 'send': 108, 'new': 109, 'find': 110, 'offer': 111, 'set': 112, 'discuss': 113, 'kindly': 114, 'document': 115, 'it’s': 116, 'afraid': 117, 'much': 118, 'file': 119, 'learn': 120, 'good': 121, 'week': 122, 'provide': 123, 'request': 124, 'reach': 125, 'apologize': 126, 'assure': 127, 'through': 128, 'experience': 129, 'previous': 130, 'back': 131, 'confidential': 132, 'sharing': 133, 'now': 134, 'give': 135, 'per': 136, 'unfortunately': 137, 'hear': 138, 'next': 139, 'schedule': 140, 'i’ve': 141, 'really': 142, 'i’ll': 143, 'there': 144, 'you’re': 145, 'connect': 146, 'details': 147, 'concerns': 148, 'requested': 149, 'further': 150, 'future': 151, 'apology': 152, 'deeply': 153, 'want': 154, 'over': 155, 'shared': 156, 'following': 157, 'review': 158, 'contract': 159, 'vendor': 160, 'appreciated': 161, 'or': 162, 'don’t': 163, 'hesitate': 164, 'accept': 165, 'tell': 166, 'invite': 167, 'shortly': 168, 'summer': 169, 'products': 170, 'excited': 171, 'team': 172, 'start': 173, 'helpful': 174, 'considering': 175, 'address': 176, 'than': 177, 'happy': 178, 'end': 179, 'apologies': 180, 'reply': 181, 'right': 182, 'go': 183, 'making': 184, 'follow': 185, 'got': 186, 'meeting': 187, 'let’s': 188, 'project': 189, 'quick': 190, 'discussed': 191, 'anything': 192, 'continued': 193, 'insights': 194, 'news': 195, 'proceed': 196, 'cancellation': 197, 'company': 198, 'see': 199, 'very': 200, 'additional': 201, 'by': 202, 'highly': 203, 'when': 204, 'looking': 205, 'contact': 206, 'linkedin': 207, 'catalog': 208, 'read': 209, 'opportunities': 210, 'explore': 211, 'today': 212, 'leave': 213, 'discount': 214, 'well': 215, 'having': 216, 'meet': 217, 'event': 218, 'specific': 219, 'potential': 220, 'reaching': 221, 'taking': 222, 'write': 223, 'regarding': 224, 'pfa': 225, 'answer': 226, 'late': 227, 'issue': 228, 'product': 229, 'matter': 230, 'token': 231, 'reminder': 232, 'keeping': 233, 'quickly': 234, 'did': 235, 'treat': 236, 'ensure': 237, 'such': 238, 'mind': 239, 'clear': 240, 'expectations': 241, 'highlight': 242, 'far': 243, 'convenience': 244, 'collaboration': 245, 'valuable': 246, 'without': 247, 'pleasure': 248, 'name': 249, 'regards': 250, 'talk': 251, 'understanding': 252, 'greatly': 253, 'assistance': 254, 'these': 255, 'ask': 256, 'took': 257, 'started': 258, 'enjoyed': 259, 'why': 260, 'everyone': 261, 'explain': 262, 'said': 263, 'wish': 264, 'available': 265, 'able': 266, 'unable': 267, 'after': 268, 'due': 269, 'thursday': 270, 'tomorrow': 271, 'recently': 272, 'you’d': 273, 'coming': 274, 'friday': 275, 'also': 276, 'before': 277, 'add': 278, 'recommended': 279, 'purchase': 280, 'plan': 281, 'personalized': 282, 'stay': 283, 'role': 284, 'miss': 285, 'sure': 286, 'hey': 287, 'hi': 288, 'hello': 289, 'morning': 290, 'dear': 291, 'concern': 292, 'amazing': 293, 'weekend': 294, 'glad': 295, 'solutions': 296, 'case': 297, 'other': 298, 'steps': 299, 'repeat': 300, 'extend': 301, 'full': 302, 'actively': 303, 'raised': 304, 'negative': 305, 'committed': 306, 'service': 307, 'situation': 308, 'solution': 309, 'friendly': 310, 'conversation': 311, 'must': 312, 'chance': 313, 'into': 314, 'remind': 315, 'task': 316, 'updates': 317, 'brainstorm': 318, 'believe': 319, 'reference': 320, 'sensitive': 321, 'remains': 322, 'else': 323, 'heads': 324, 'attaching': 325, 'both': 326, 'refer': 327, 'discussion': 328, 'records': 329, 'gratitude': 330, 'enthusiasm': 331, 'prompt': 332, 'hard': 333, 'bad': 334, 'way': 335, 'canceling': 336, 'requesting': 337, 'termination': 338, 'serves': 339, 'official': 340, 'notice': 341, 'cancel': 342, 'communication': 343, 'chat': 344, 'sincerely': 345, 'wishes': 346, 'during': 347, 'hearing': 348, 'consideration': 349, 'interest': 350, 'challenges': 351, 'we’ll': 352, 'wonderful': 353, 'bottom': 354, 'attending': 355, 'together': 356, 'thoughts': 357, 'sending': 358, 'replying': 359, 'responding': 360, 'response': 361, 'changes': 362, 'sign': 363, 'grateful': 364, 'didn’t': 365, 'fully': 366, 'quite': 367, 'light': 368, 'use': 369, 'they': 370, 'already': 371, 'loop': 372, 'think': 373, 'views': 374, 'waiting': 375, 'via': 376, 'comfortable': 377, 'feasible': 378, 'book': 379, 'accordingly': 380, 'won’t': 381, 'scheduled': 382, 'taken': 383, 'against': 384, 'rules': 385, 'efforts': 386, 'domain': 387, 'advance': 388, 'everything': 389, 'ready': 390, 'meantime': 391, 'patience': 392, 'luck': 393, 'welcome': 394, 'leaving': 395, 'open': 396, 'came': 397, 'post': 398, 'options': 399, 'later': 400, 'we’ve': 401, 'walk': 402, 'packages': 403, '12': 404, '–': 405, '5': 406, 'p': 407, 'm': 408, 'est': 409, 'chatting': 410, 'save': 411, 'improve': 412, 'suggestions': 413, 'ps': 414, 'lot': 415, 'say': 416, 'skills': 417, 'video': 418, 'current': 419, 'portfolio': 420, 'creative': 421, 'opportunity': 422, 'past': 423, 'learning': 424, 'career': 425, 'coffee': 426, 'subscribe': 427, 'network': 428, 'repost': 429, 'pin': 430, 'survey': 431, 'exclusive': 432, 'tailored': 433, 'tickets': 434, 'discover': 435, 'customer': 436, 'cta': 437, 'examples': 438, 'rate': 439, 'customized': 440, 'special': 441, 'connected': 442, 'reached': 443, 'job': 444, 'done': 445, 'years': 446, 'going': 447, 'sick': 448, 'absence': 449, '10': 450, 'store': 451, 'student': 452, 'interested': 453, 'afternoon': 454, 'evening': 455, 'sir': 456, 'madam': 457, 'whom': 458, 'whomsoever': 459, 'finds': 460, 'restful': 461, 'inquire': 462, 'introduce': 463, 'immensely': 464, 'issues': 465, 'causing': 466, 'delay': 467, \"you're\": 468, 'wondering': 469, 'question': 470, 'misunderstanding': 471, 'necessary': 472, 'resolve': 473, 'heartfelt': 474, 'responsibility': 475, 'happened': 476, 'shall': 477, 'happen': 478, 'trouble': 479, 'you’ve': 480, 'delays': 481, 'resolving': 482, 'rest': 483, 'assured': 484, 'immediate': 485, 'action': 486, 'rectify': 487, 'prevent': 488, 'recurrence': 489, 'compensation': 490, 'offering': 491, 'alternative': 492, 'base': 493, 'busy': 494, 'deadline': 495, 'close': 496, 'circle': 497, 'aside': 498, 'arrange': 499, 'block': 500, 'calendar': 501, 'half': 502, 'hour': 503, \"3'o\": 504, 'clock': 505, 'availability': 506, 'only': 507, 'between': 508, 'anyone': 509, 'strictly': 510, 'outline': 511, 'same': 512, 'page': 513, 'deadlines': 514, 'avoid': 515, 'misunderstandings': 516, 'rundown': 517, 'attachment': 518, 'earliest': 519, 'required': 520, 'perusal': 521, 'moment': 522, 'wouldn’t': 523, 'difficult': 524, 'deliver': 525, 'effective': 526, 'cheers': 527, 'one': 528, 'until': 529, 'yours': 530, 'warmly': 531, 'catching': 532, 'attention': 533, 'proves': 534, 'useful': 535, 'once': 536, 'cooperation': 537, 'partnership': 538, 'update': 539, 'promptly': 540, 'clarification': 541, 'trip': 542, 'away': 543, 'needed': 544, 'holiday': 545, 'season': 546, 'convention': 547, 'purpose': 548, 'yesterday’s': 549, 'presentation': 550, 'informative': 551, 'concerning': 552, 'connection': 553, 'interaction': 554, 'received': 555, 'went': 556, 'yesterday': 557, 'month': 558, 'suggestion': 559, 'asking': 560, 'longer': 561, 'usual': 562, 'while': 563, 'since': 564, 'condolences': 565, 'inconveniences': 566, 'attachments': 567, 'enclosed': 568, 'made': 569, 'bold': 570, 'red': 571, 'blue': 572, 'comments': 573, 'sent': 574, 'pdf': 575, 'contents': 576, 'form': 577, 'here’s': 578, 'two': 579, 'main': 580, 'below': 581, 'clarifications': 582, 'shed': 583, 'topic': 584, 'clarify': 585, 'feature': 586, 'mistaken': 587, 'mean': 588, 'words': 589, 'phrases': 590, 'someone': 591, 'told': 592, 'notifying': 593, 'note': 594, 'informed': 595, 'posted': 596, 'updated': 597, 'approval': 598, 'ok': 599, 'thumbs': 600, 'green': 601, 'totally': 602, 'ahead': 603, 'he': 604, 'approved': 605, 'monday': 606, 'convenient': 607, 'interview': 608, 'rescheduled': 609, 'cannot': 610, 'careful': 611, 'decision': 612, 'rain': 613, 'seems': 614, 'unlikely': 615, 'put': 616, 'despite': 617, 'putting': 618, 'answered': 619, 'there’s': 620, 'okay': 621, 'confident': 622, 'problem': 623, 'trust': 624, 'inquiry': 625, 'accepting': 626, 'applications': 627, 'graduate': 628, 'program': 629, 'endeavors': 630, 'refrain': 631, 'window': 632, 'desk': 633, 'each': 634, 'night': 635, 'water': 636, 'cubicle': 637, 'saw': 638, 'own': 639, 'operate': 640, 'twenty': 641, 'minutes': 642, 'carry': 643, 'pricing': 644, 'few': 645, 'slots': 646, 'which': 647, 'crucial': 648, 'aspect': 649, 'however': 650, 'consuming': 651, 'challenging': 652, 'where': 653, 'easy': 654, 'hours': 655, 'otherwise': 656, 'instead': 657, 'addition': 658, 'quality': 659, 'analyzing': 660, 'generating': 661, 'improvement': 662, 'recommend': 663, 'trying': 664, 'signing': 665, 'trial': 666, 'began': 667, 'article': 668, 'strong': 669, 'opinions': 670, 'conducted': 671, 'research': 672, 'realized': 673, 'most': 674, 'completing': 675, 'intensive': 676, 'confidently': 677, 'changed': 678, 'fact': 679, 'piece': 680, 'maintain': 681, 'ways': 682, 'discovered': 683, 'freelance': 684, 'writer': 685, 'restaurant': 686, 'hospitality': 687, 'brands': 688, 'include': 689, 'lose': 690, 'track': 691, 'list': 692, 'discovery': 693, 'found': 694, 'profile': 695, 'seeing': 696, 'opening': 697, 'latest': 698, 'across': 699, 'researching': 700, 'particularly': 701, 'fit': 702, 'company’s': 703, 'needs': 704, 'background': 705, 'contribute': 706, 'success': 707, 'brief': 708, 'connecting': 709, 'seen': 710, 'grow': 711, 'looks': 712, 'thriving': 713, 'currently': 714, 'passion': 715, 'peers': 716, 'strengthened': 717, 'skill': 718, 'mutually': 719, 'beneficial': 720, 'course': 721, 'challenge': 722, 'experiences': 723, 'short': 724, 'virtual': 725, 'weeks': 726, 'possibility': 727, 'buy': 728, 'appointment': 729, 'guide': 730, 'features': 731, 'tiktok': 732, 'awaits': 733, 'order': 734, 'cart': 735, 'claim': 736, 'join': 737, 'community': 738, 'upgrade': 739, 'services': 740, 'blog': 741, 'works': 742, 'watch': 743, 'testimonials': 744, 'faqs': 745, 'view': 746, 'resources': 747, 'social': 748, 'friends': 749, 'spread': 750, 'word': 751, 'followers': 752, 'facebook': 753, 'tag': 754, 'friend': 755, 'snap': 756, 'opinion': 757, 'voice': 758, 'invitation': 759, 'deals': 760, 'unlock': 761, 'ideal': 762, 'quote': 763, 'lovely': 764, 'transition': 765, 'learned': 766, 'aren’t': 767, 'huge': 768, 'growth': 769, 'exciting': 770, 'colleagues': 771, 'afforded': 772, 'proud': 773, 'year': 774, 'although': 775, 'chapter': 776, 'goodbye': 777, 'person': 778, 'sad': 779, 'excellent': 780, 'coworkers': 781, 'joy': 782, 'part': 783, 'spending': 784, 'freedom': 785, 'chats': 786, 'cheering': 787, 'retirement': 788, 'internship': 789, 'helped': 790, 'couldn’t': 791, 'bittersweet': 792, 'embark': 793, 'mentorship': 794, 'invaluable': 795, 'emailing': 796, 'account': 797, 'come': 798, 'fever': 799, 'checking': 800, 'emails': 801, 'urgent': 802, 'cell': 803, 'phone': 804, 'aim': 805, 'illness': 806, 'being': 807, 'formally': 808, 'period': 809, 'medical': 810, 'condition': 811, 'arisen': 812, 'doctor': 813, 'extended': 814, 'off': 815, 'recover': 816, 'expected': 817, 'smooth': 818, 'workflow': 819, 'refunded': 820, 'funds': 821, 'should': 822, 'promo': 823, 'code': 824, 'unpleasant': 825, 'frustration': 826, 'forwarded': 827, 'complaint': 828, 'management': 829, 'never': 830, 'happens': 831, 'discounts': 832, 'annual': 833, 'coding': 834, 'conference': 835, 'university': 836, 'ticket': 837, 'price': 838, 'too': 839, 'high': 840, 'educational': 841, 'complete': 842, 'projects': 843, 'pending': 844, 'tasks': 845, 'vacation': 846, 'website': 847, 'still': 848, 'guest': 849, 'mobile': 850, 'industry': 851, 'audience': 852, 'collaborating': 853, 'she': 854, 'providing': 855, 'technical': 856, 'users': 857, 'enjoy': 858, 'greet': 859}\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# assigns each word a unique number/index\n",
    "tokenizer.fit_on_texts(prompts.phrases)\n",
    "\n",
    "print(tokenizer.word_index)\n",
    "# for s in tokenizer.word_index:\n",
    "    # print(s for s )\n",
    "# help(tokenizer)\n",
    "\n",
    "# print(tokenizer.word_index['Hey'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "44VahqKdAjr9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0 ...   0   0 287]\n",
      " [  0   0   0 ...   0   0 288]\n",
      " [  0   0   0 ...   0   0 289]\n",
      " ...\n",
      " [  0   0   0 ...   0 101  59]\n",
      " [  0   0   0 ... 101  59   1]\n",
      " [  0   0   0 ...  59   1 859]]\n"
     ]
    }
   ],
   "source": [
    "def sentence_to_padded_sequences(phrases):\n",
    "    \n",
    "  input_sequences = []\n",
    "  # loop for each given sentence in list of sentences phrases\n",
    "  for phrase in phrases:\n",
    "    \n",
    "    # texts_to_sequences convert the sentence to list of indexes corresponding to word in dictionary\n",
    "    tokenized_sentence = tokenizer.texts_to_sequences([phrase])[0]\n",
    "    # print(tokenized_sentence)\n",
    "    # training for each sentence by iterating over no. of words taken to train in an iteration\n",
    "    for i in range(len(tokenized_sentence)):\n",
    "      input_sequences.append(tokenized_sentence[:i+1])\n",
    "  global vectorLength \n",
    "  vectorLength = max([len(x) for x in input_sequences])\n",
    "  \n",
    "  # empty list of sequences initialized\n",
    "  padded_input_sequences = []\n",
    "  \n",
    "  # padded_input_sequences put zeroes in place of empty words\n",
    "  # e.g. my sentence is                      -   \"I hope this email finds you well\"\n",
    "  # after mapping to index in dectionary     -   \"3  42   7    28    444   2  212\"  \n",
    "  # padding of zeros are added in beginnning -   \"0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 42 7 28 444 2 212\" \n",
    "  # now the length of vector becomes 25 with zeros added\n",
    "  padded_input_sequences = pad_sequences(input_sequences, maxlen = vectorLength, padding='pre')\n",
    "  return padded_input_sequences\n",
    "\n",
    "X = sentence_to_padded_sequences(prompts.phrases)\n",
    "print(X)\n",
    "# print(X[24])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "rs1NPitwSgzk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[287 288 289 ...  59   1 859]\n"
     ]
    }
   ],
   "source": [
    "X = sentence_to_padded_sequences(prompts.phrases)[:,:-1]\n",
    "y = sentence_to_padded_sequences(prompts.phrases)[:,-1]\n",
    "print(y)\n",
    "dictionaryLength = len(tokenizer.word_index)\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# convert the desired values to an array where all values are zero except at dictionary index which is one\n",
    "y = to_categorical(y,num_classes=dictionaryLength+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "\n",
    "# creating our LSTM model\n",
    "model = Sequential()\n",
    "model.add(Embedding(dictionaryLength+1, 400, input_length=vectorLength-1))\n",
    "model.add(LSTM(dictionaryLength+1))\n",
    "model.add(Dense( dictionaryLength+1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "# model.summary()\n",
    "tf.keras.utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LpFUCALCfJRR",
    "outputId": "96d67a78-3c2e-4462-b2a8-2655c303af8d",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:From C:\\Users\\Sachit\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Sachit\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "151/151 [==============================] - 81s 448ms/step - loss: 5.7166 - accuracy: 0.0735\n",
      "Epoch 2/10\n",
      "151/151 [==============================] - 66s 438ms/step - loss: 4.9335 - accuracy: 0.1347\n",
      "Epoch 3/10\n",
      "151/151 [==============================] - 61s 407ms/step - loss: 4.1224 - accuracy: 0.2167\n",
      "Epoch 4/10\n",
      "151/151 [==============================] - 63s 416ms/step - loss: 3.2874 - accuracy: 0.3216\n",
      "Epoch 5/10\n",
      "151/151 [==============================] - 56s 369ms/step - loss: 2.5132 - accuracy: 0.4252\n",
      "Epoch 6/10\n",
      "151/151 [==============================] - 64s 422ms/step - loss: 1.8653 - accuracy: 0.5643\n",
      "Epoch 7/10\n",
      "151/151 [==============================] - 65s 427ms/step - loss: 1.4340 - accuracy: 0.6687\n",
      "Epoch 8/10\n",
      "151/151 [==============================] - 61s 402ms/step - loss: 1.2309 - accuracy: 0.7129\n",
      "Epoch 9/10\n",
      "151/151 [==============================] - 58s 384ms/step - loss: 1.1249 - accuracy: 0.7343\n",
      "Epoch 10/10\n",
      "151/151 [==============================] - 60s 400ms/step - loss: 1.0629 - accuracy: 0.7480\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x208926f1750>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,y,epochs=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PGeYGwCMfTus",
    "outputId": "2d508555-b83e-470e-e7e5-1b5c10cce70b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "0.99998933\n",
      "could you please\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "0.99991584\n",
      "could you please repeat\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "0.9999583\n",
      "could you please repeat what\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "0.9999882\n",
      "could you please repeat what you\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "0.9999573\n",
      "could you please repeat what you said\n"
     ]
    }
   ],
   "source": [
    "def predict(sentence: str):\n",
    "    \"\"\"\n",
    "    Prints the word predictions based on a given sentence, limited to a maximum of N words\n",
    "    ## Parameters\n",
    "    sentence : string which is the initial sentence \n",
    "    \"\"\"\n",
    "    for i in range(5):\n",
    "        \n",
    "        # tokenize\n",
    "        token_text = tokenizer.texts_to_sequences([sentence])[0]\n",
    "        \n",
    "        # padding\n",
    "        padded_token_text = pad_sequences([token_text], maxlen=vectorLength-1, padding='pre')\n",
    "        \n",
    "        # predict\n",
    "        arr = model.predict(padded_token_text)\n",
    "        print(max(arr[0]))\n",
    "\n",
    "        # if it is predicting 6th word and if it's probability is lower than 0.2 it should not predict word as it will be absurd predictions\n",
    "        if(max(arr[0]) < 0.20 and i>4):\n",
    "            break\n",
    "        pos = np.argmax(arr)\n",
    "        for word,index in tokenizer.word_index.items():\n",
    "            if index == pos:\n",
    "                sentence = sentence + \" \" + word\n",
    "                print(sentence)\n",
    "\n",
    "\n",
    "text = \"could you\"\n",
    "predict(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 57ms/step\n",
      "0.9999481\n",
      "i have attached\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "0.999972\n",
      "i have attached the\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "0.9999935\n",
      "i have attached the required\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "0.9999968\n",
      "i have attached the required documents\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "0.99999845\n",
      "i have attached the required documents for\n"
     ]
    }
   ],
   "source": [
    "predict(\"i have\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 94ms/step\n",
      "0.9999182\n",
      "to whom it\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "0.9999902\n",
      "to whom it may\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "0.99999696\n",
      "to whom it may concern\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "0.99946356\n",
      "to whom it may concern some\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "0.99999034\n",
      "to whom it may concern some additional\n"
     ]
    }
   ],
   "source": [
    "predict(\"to whom\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# saving the model and the dictionary in the extension folder\n",
    "# import joblib\n",
    "# joblib.dump(model, \"./extension/model\")\n",
    "# model.save(\"./extension/model.h5\")\n",
    "# tokenizer_json = tokenizer.to_json()\n",
    "# with open('./extension/tokenizer.json', 'w', encoding='utf-8') as f:\n",
    "#     f.write(json.dumps(tokenizer_json, ensure_ascii=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"model\")\n",
    "# import tensorflowjs\n",
    "# tensorflowjs.converters.save_keras_model(model, \"extension\")\n",
    "# model_json = model.to_json()\n",
    "# with open(\"./extension/model.json\", \"w\") as f:\n",
    "#     json.dump(model_json, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
